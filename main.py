import os
import sys
import joblib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

# è·¯å¾„é…ç½®ï¼šè‡ªåŠ¨è·å–é¡¹ç›®æ ¹ç›®å½•ï¼Œæ·»åŠ srcåˆ°ç¯å¢ƒå˜é‡ï¼ˆå¯¼å…¥æ ¸å¿ƒæ¨¡å—ï¼‰
def get_project_paths():
    PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
    SRC_DIR = os.path.join(PROJECT_ROOT, "src")
    if os.path.isdir(SRC_DIR) and SRC_DIR not in sys.path:
        sys.path.append(SRC_DIR)
    return {
        "root": PROJECT_ROOT, "src": SRC_DIR,
        "models": os.path.join(PROJECT_ROOT, "models"),
        "results": os.path.join(PROJECT_ROOT, "results"),
        "data": os.path.join(PROJECT_ROOT, "data")
    }

# åˆå§‹åŒ–è·¯å¾„
PATHS = get_project_paths()

# å¯¼å…¥srcæ¨¡å—ï¼Œæ·»åŠ å‹å¥½çš„é”™è¯¯æç¤º
try:
    from src.feature_engineering import build_feature_preprocessor
    from src.model_evaluation import evaluate_model, plot_model_comparison, plot_feature_importance, plot_pred_vs_true
    from src.predict import predict_gpa
except ImportError as e:
    raise ImportError(
        f"âŒ å¯¼å…¥æ ¸å¿ƒæ¨¡å—å¤±è´¥ï¼š{e}\nè¯·ç¡®è®¤ï¼š\n"
        f"1. srcç›®å½•å­˜åœ¨ä¸”åŒ…å«feature_engineering.pyã€model_evaluation.pyã€predict.py\n"
        f"2. æ‰€æœ‰æ–‡ä»¶å‡ä¸ºä¿®å¤åçš„ç‰ˆæœ¬ï¼ˆæ— Floatå¯¼å…¥é”™è¯¯ï¼‰"
    ) from e

# å…¨å±€å˜é‡ï¼šç‰¹å¾é¢„å¤„ç†æµæ°´çº¿ï¼ˆä¾›è¯„ä¼°å‡½æ•°ä½¿ç”¨ï¼‰
preprocessor = None

def init_directories():
    """åˆå§‹åŒ–é¡¹ç›®ç›®å½•ï¼šè‡ªåŠ¨åˆ›å»ºmodels/results/data/docsç­‰ï¼Œé˜²æ­¢æ–‡ä»¶ä¸å­˜åœ¨æŠ¥é”™"""
    for dir_path in PATHS.values():
        os.makedirs(dir_path, exist_ok=True)
    print(f"âœ… é¡¹ç›®ç›®å½•åˆå§‹åŒ–å®Œæˆï¼š{list(PATHS.keys())}")

def load_and_clean_data():
    """æ•°æ®åŠ è½½+é¢„å¤„ç†ï¼šè¯»å–csvï¼Œç¼ºå¤±å€¼/å¼‚å¸¸å€¼å¤„ç†ï¼Œé€‚é…æ–°ç‰¹å¾"""
    data_path = os.path.join(PATHS["data"], "simulated_data.csv")
    # æ ¡éªŒæ•°æ®æ–‡ä»¶
    if not os.path.exists(data_path):
        raise FileNotFoundError(f"âŒ æ•°æ®æ–‡ä»¶ç¼ºå¤±ï¼š{data_path}\nè¯·å…ˆè¿è¡Œpython data/generate_simulated_data.pyç”Ÿæˆæ•°æ®")

    # è¯»å–æ•°æ®ï¼ˆå…¼å®¹utf-8-sig/gbkï¼Œè§£å†³ä¸­æ–‡ä¹±ç ï¼‰
    try:
        df = pd.read_csv(data_path, encoding="utf-8-sig")
    except UnicodeDecodeError:
        df = pd.read_csv(data_path, encoding="gbk")

    print(f"âœ… æˆåŠŸè¯»å–æ•°æ®ï¼š{data_path}")
    print(f"ğŸ“Š åŸå§‹æ•°æ®è§„æ¨¡ï¼š{df.shape[0]} æ¡ Ã— {df.shape[1]} åˆ—")
    print(f"ğŸ“‹ æ•°æ®åˆ—åï¼š{list(df.columns)}")

    # æ ¡éªŒæ ¸å¿ƒåˆ—ï¼ˆ8ç‰¹å¾+1ç»©ç‚¹ï¼‰
    required_cols = [
        "gpa", "major", "gender", "attendance", "homework_completion",
        "lib_borrow", "club_participation", "class_interaction", "exam_score"
    ]
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"âŒ æ•°æ®ç¼ºå¤±æ ¸å¿ƒåˆ—ï¼š{missing_cols}")

    # ç¼ºå¤±å€¼å¤„ç†ï¼ˆæœ¬æ¨¡æ‹Ÿæ•°æ®æ— ç¼ºå¤±ï¼Œä¿ç•™é€»è¾‘é€‚é…çœŸå®æ•°æ®ï¼‰
    print("\nğŸ” ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š")
    missing_stats = df.isnull().sum()
    print(missing_stats[missing_stats > 0] if missing_stats.sum() > 0 else "æ— ç¼ºå¤±å€¼")
    if missing_stats.sum() > 0:
        num_cols = df.select_dtypes(include=[np.number]).columns
        df[num_cols] = df[num_cols].fillna(df[num_cols].median())  # æ•°å€¼ç‰¹å¾ä¸­ä½æ•°å¡«å……
        cat_cols = df.select_dtypes(include=[object]).columns
        df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])  # ç±»åˆ«ç‰¹å¾ä¼—æ•°å¡«å……
        print("âœ… ç¼ºå¤±å€¼å·²å®Œæˆå¡«å……")

    # å¼‚å¸¸å€¼å¤„ç†ï¼šæŒ‰ä¸šåŠ¡è§„åˆ™é™åˆ¶èŒƒå›´
    print("\nğŸ”§ å¼‚å¸¸å€¼å¤„ç†ï¼š")
    clip_rules = {
        "gpa": (1.0, 4.0), "attendance": (20, 32), "homework_completion": (0.6, 1.0),
        "lib_borrow": (0, 10), "class_interaction": (0, 20), "exam_score": (60, 100)
    }
    for col, (min_val, max_val) in clip_rules.items():
        error_count = ((df[col] < min_val) | (df[col] > max_val)).sum()
        if error_count > 0:
            df[col] = df[col].clip(min_val, max_val)
            print(f"   - {col}ï¼šä¿®æ­£{error_count}æ¡å¼‚å¸¸å€¼ï¼ˆèŒƒå›´{min_val}-{max_val}ï¼‰")
    print("âœ… å¼‚å¸¸å€¼å¤„ç†å®Œæˆ")

    # æ•°æ®ç±»å‹è½¬æ¢ï¼ˆç¡®ä¿ç±»åˆ«ç‰¹å¾ä¸ºæ•´æ•°ï¼‰
    df["gender"] = df["gender"].astype(int)
    df["club_participation"] = df["club_participation"].astype(int)
    print("âœ… æ•°æ®ç±»å‹è½¬æ¢å®Œæˆ")

    print(f"\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼æœ€ç»ˆè§„æ¨¡ï¼š{df.shape[0]} æ¡ Ã— {df.shape[1]} åˆ—")
    return df

def load_data():
    """åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†ï¼šç‰¹å¾X + æ ‡ç­¾yï¼Œæµ‹è¯•é›†å æ¯”20%"""
    df = load_and_clean_data()
    X = df.drop("gpa", axis=1)  # ç‰¹å¾çŸ©é˜µï¼šç§»é™¤æ ‡ç­¾åˆ—
    y = df["gpa"]               # æ ‡ç­¾å‘é‡ï¼šç»©ç‚¹
    # éšæœºåˆ’åˆ†ï¼Œå›ºå®šç§å­ä¿è¯å¯å¤ç°
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print("ğŸ“ æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼š")
    print(f"   - è®­ç»ƒé›†ï¼š{X_train.shape[0]} æ¡")
    print(f"   - æµ‹è¯•é›†ï¼š{X_test.shape[0]} æ¡")
    return X_train, X_test, y_train, y_test

def train_models(X_train_processed, y_train):
    """è®­ç»ƒ3ä¸ªæ¨¡å‹ï¼šçº¿æ€§å›å½’ï¼ˆåŸºçº¿ï¼‰ã€å†³ç­–æ ‘ï¼ˆç½‘æ ¼è°ƒä¼˜ï¼‰ã€éšæœºæ£®æ—ï¼ˆé›†æˆï¼‰"""
    models = {}
    models_dir = PATHS["models"]

    # 1. çº¿æ€§å›å½’ï¼ˆåŸºçº¿æ¨¡å‹ï¼Œæ‹Ÿåˆæ•ˆæœæœ€ä¼˜ï¼‰
    print("\nğŸš€ å¼€å§‹è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹ï¼ˆåŸºçº¿ï¼‰...")
    lr_model = LinearRegression()
    lr_model.fit(X_train_processed, y_train)
    lr_path = os.path.join(models_dir, "linear_regression.pkl")
    joblib.dump(lr_model, lr_path)
    print(f"âœ… çº¿æ€§å›å½’æ¨¡å‹å·²ä¿å­˜ï¼š{lr_path}")
    models["çº¿æ€§å›å½’"] = {"model": lr_model, "path": lr_path}

    # 2. å†³ç­–æ ‘ï¼ˆç½‘æ ¼æœç´¢è°ƒä¼˜æ ¸å¿ƒå‚æ•°ï¼‰
    print("\nğŸš€ å¼€å§‹è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ï¼ˆç½‘æ ¼æœç´¢è°ƒä¼˜ï¼‰...")
    dt_params = {"max_depth": [5, 10, 15], "min_samples_split": [10, 20, 30]}
    dt_model = DecisionTreeRegressor(random_state=42)
    dt_grid = GridSearchCV(dt_model, dt_params, cv=5, scoring="r2", n_jobs=-1)
    dt_grid.fit(X_train_processed, y_train)
    best_dt = dt_grid.best_estimator_
    print(f"ğŸ”§ å†³ç­–æ ‘æœ€ä¼˜å‚æ•°ï¼š{dt_grid.best_params_}")
    dt_path = os.path.join(models_dir, "decision_tree.pkl")
    joblib.dump(best_dt, dt_path)
    print(f"âœ… å†³ç­–æ ‘æ¨¡å‹å·²ä¿å­˜ï¼š{dt_path}")
    models["å†³ç­–æ ‘"] = {"model": best_dt, "path": dt_path}

    # 3. éšæœºæ£®æ—ï¼ˆé›†æˆå­¦ä¹ ï¼Œä¼˜åŒ–å‚æ•°æå‡æ‹Ÿåˆï¼‰
    print("\nğŸš€ å¼€å§‹è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ï¼ˆé›†æˆå­¦ä¹ ï¼‰...")
    rf_model = RandomForestRegressor(n_estimators=200, max_depth=12, random_state=42, n_jobs=-1)
    rf_model.fit(X_train_processed, y_train)
    rf_path = os.path.join(models_dir, "random_forest.pkl")
    joblib.dump(rf_model, rf_path)
    print(f"âœ… éšæœºæ£®æ—æ¨¡å‹å·²ä¿å­˜ï¼š{rf_path}")
    models["éšæœºæ£®æ—"] = {"model": rf_model, "path": rf_path}

    return models

def evaluate_models(models, X_test_processed, y_test):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œç”Ÿæˆ3å¼ è¯„ä¼°å›¾è¡¨"""
    print("\nğŸ“Š æ­¥éª¤4ï¼šæ¨¡å‹è¯„ä¼°")
    print("-" * 30)
    metrics_list = []
    # é¢„æµ‹å„æ¨¡å‹ç»“æœ
    y_pred_lr = models["çº¿æ€§å›å½’"]["model"].predict(X_test_processed)
    y_pred_dt = models["å†³ç­–æ ‘"]["model"].predict(X_test_processed)
    y_pred_rf = models["éšæœºæ£®æ—"]["model"].predict(X_test_processed)
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    metrics_list.append(evaluate_model(y_test, y_pred_lr, "çº¿æ€§å›å½’"))
    metrics_list.append(evaluate_model(y_test, y_pred_dt, "å†³ç­–æ ‘"))
    metrics_list.append(evaluate_model(y_test, y_pred_rf, "éšæœºæ£®æ—"))
    # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    plot_model_comparison(metrics_list, PATHS["root"])
    plot_feature_importance(models["éšæœºæ£®æ—"]["model"], preprocessor, PATHS["root"])
    plot_pred_vs_true(y_test, y_pred_lr, PATHS["root"])  # ç”¨çº¿æ€§å›å½’ç»“æœç»˜å›¾ï¼ˆæ‹Ÿåˆæœ€å¥½ï¼‰
    return metrics_list

def run_prediction_example():
    """è¿è¡Œç¤ºä¾‹é¢„æµ‹ï¼š2ä¸ªå­¦ç”Ÿæ¡ˆä¾‹ï¼Œå±•ç¤ºé¢„æµ‹æ•ˆæœ"""
    print("\nğŸ“ æ­¥éª¤5ï¼šå­¦ç”Ÿç»©ç‚¹é¢„æµ‹ç¤ºä¾‹")
    print("-" * 30)
    # ç¤ºä¾‹1ï¼šä¼˜ç§€å­¦ç”Ÿï¼ˆé«˜ç‰¹å¾å€¼ï¼‰
    student1 = {
        "major": "äººå·¥æ™ºèƒ½å­¦é™¢", "gender": 1, "attendance": 30, "homework_completion": 0.98,
        "lib_borrow": 4, "club_participation": 1, "class_interaction": 18, "exam_score": 95
    }
    # ç¤ºä¾‹2ï¼šå­¦ä¸šé¢„è­¦å­¦ç”Ÿï¼ˆä½ç‰¹å¾å€¼ï¼‰
    student2 = {
        "major": "æ–‡å­¦é™¢", "gender": 0, "attendance": 22, "homework_completion": 0.65,
        "lib_borrow": 6, "club_participation": 0, "class_interaction": 2, "exam_score": 62
    }
    # é¢„æµ‹å¹¶æ‰“å°ç»“æœ
    try:
        pred1 = predict_gpa(student1, PATHS["root"])
        pred2 = predict_gpa(student2, PATHS["root"])
        # è¯„çº§é€»è¾‘
        def get_rating(gpa):
            if gpa >= 3.5: return "ä¼˜ç§€ï¼ˆå»ºè®®ç”³è¯·å¥–å­¦é‡‘ï¼‰"
            elif gpa >= 2.5: return "è‰¯å¥½ï¼ˆå¯å‚ä¸å­¦æœ¯ç«èµ›ï¼‰"
            elif gpa >= 1.5: return "åˆæ ¼ï¼ˆå»ºè®®åŠ å¼ºä½œä¸šä¸å‡ºå‹¤ï¼‰"
            else: return "éœ€é¢„è­¦ï¼ˆå»ºè®®è”ç³»è¾…å¯¼å‘˜è¾…å¯¼ï¼‰"
        # æ‰“å°ç¤ºä¾‹1
        print("\nğŸ‘¨â€ğŸ“ ç¤ºä¾‹å­¦ç”Ÿ1é¢„æµ‹ï¼š")
        print("-" * 40)
        for k, v in student1.items(): print(f"{k}: {v}")
        print(f"ğŸ¯ é¢„æµ‹ç»©ç‚¹ï¼š{pred1} | ğŸ† è¯„çº§ï¼š{get_rating(pred1)}")
        # æ‰“å°ç¤ºä¾‹2
        print("\nğŸ‘©â€ğŸ“ ç¤ºä¾‹å­¦ç”Ÿ2é¢„æµ‹ï¼š")
        print("-" * 40)
        for k, v in student2.items(): print(f"{k}: {v}")
        print(f"ğŸ¯ é¢„æµ‹ç»©ç‚¹ï¼š{pred2} | ğŸ† è¯„çº§ï¼š{get_rating(pred2)}")
    except Exception as e:
        print(f"âš ï¸ ç¤ºä¾‹é¢„æµ‹å¤±è´¥ï¼š{str(e)}")

def main():
    """é¡¹ç›®ä¸»æµç¨‹ï¼šåˆå§‹åŒ–â†’åŠ è½½æ•°æ®â†’ç‰¹å¾å·¥ç¨‹â†’è®­ç»ƒæ¨¡å‹â†’è¯„ä¼°â†’ç¤ºä¾‹é¢„æµ‹"""
    global preprocessor
    print("=" * 50)
    print("ğŸ¯ å­¦ç”Ÿç»©ç‚¹ï¼ˆGPAï¼‰é¢„æµ‹é¡¹ç›® - ä¸€é”®è¿è¡Œæµç¨‹")
    print("=" * 50)
    # 1. åˆå§‹åŒ–ç›®å½•
    init_directories()
    # 2. åŠ è½½å¹¶åˆ’åˆ†æ•°æ®
    print("\nğŸ“¥ æ­¥éª¤1ï¼šæ•°æ®åŠ è½½ä¸é¢„å¤„ç†")
    print("-" * 30)
    X_train, X_test, y_train, y_test = load_data()
    # 3. ç‰¹å¾å·¥ç¨‹
    print("\nğŸ”§ æ­¥éª¤2ï¼šç‰¹å¾å·¥ç¨‹")
    print("-" * 30)
    preprocessor, _, _ = build_feature_preprocessor()
    X_train_processed = preprocessor.fit_transform(X_train)  # è®­ç»ƒé›†æ‹Ÿåˆ+è½¬æ¢
    X_test_processed = preprocessor.transform(X_test)        # æµ‹è¯•é›†ä»…è½¬æ¢
    # ä¿å­˜ç‰¹å¾æµæ°´çº¿
    preprocessor_path = os.path.join(PATHS["models"], "feature_preprocessor.pkl")
    joblib.dump(preprocessor, preprocessor_path)
    print(f"âœ… ç‰¹å¾å·¥ç¨‹æµæ°´çº¿å·²ä¿å­˜ï¼š{preprocessor_path}")
    print(f"âœ… ç‰¹å¾è½¬æ¢å®Œæˆï¼å¤„ç†åç‰¹å¾ç»´åº¦ï¼š{X_train_processed.shape[1]}")
    # 4. è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ æ­¥éª¤3ï¼šæ¨¡å‹è®­ç»ƒ")
    print("-" * 30)
    models = train_models(X_train_processed, y_train)
    # 5. è¯„ä¼°æ¨¡å‹
    evaluate_models(models, X_test_processed, y_test)
    # 6. ç¤ºä¾‹é¢„æµ‹
    run_prediction_example()
    # å®Œæˆæç¤º
    print("\nğŸ‰ é¡¹ç›®å…¨æµç¨‹è¿è¡Œå®Œæˆï¼")
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼š{PATHS['models']}")
    print(f"ğŸ“ è¯„ä¼°å›¾è¡¨è·¯å¾„ï¼š{PATHS['results']}")
    print(f"ğŸ–¥ï¸  å¯è§†åŒ–GUIè¿è¡Œï¼špython gui.py")

if __name__ == "__main__":
    # å¼ºåˆ¶ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸ºå·¥ä½œç›®å½•ï¼Œé˜²æ­¢è·¯å¾„é”™è¯¯
    os.chdir(PATHS["root"])
    # å…¨å±€å¼‚å¸¸æ•è·ï¼Œå‹å¥½æç¤º
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é¡¹ç›®è¿è¡Œå¤±è´¥ï¼š{str(e)}")
        sys.exit(1)